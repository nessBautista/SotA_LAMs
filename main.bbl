% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{1}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{schick2023toolformer}
T.~Schick, J.~Dwivedi-Yu, R.~Dess√¨, R.~Raileanu, M.~Lomeli, L.~Zettlemoyer, N.~Cancedda, and T.~Scialom, ``Toolformer: Language models can teach themselves to use tools,'' \emph{arXiv preprint arXiv:2302.04761}, Feb 2023, [Online]. Available: https://arxiv.org/abs/2302.04761. [Accessed: Mar. 14, 2025].

\bibitem{qin2023toolllm}
Y.~Qin, S.~Liang, H.~Ye, K.~Zhu, L.~Yan, Y.~Lu, Y.~Lin, X.~Cong, X.~Tang, B.~Qian, S.~Zhao, L.~Hong, R.~Tian, R.~Xie, J.~Zhou, M.~Gerstein, D.~Li, Z.~Liu, and M.~Sun, ``Toolllm: Facilitating large language models to master 16000+ real-world apis,'' \emph{arXiv preprint arXiv:2307.16789}, Oct 2023, [Online]. Available: https://arxiv.org/abs/2307.16789. [Accessed: Mar. 14, 2025].

\bibitem{wang2025lam}
L.~Wang, F.~Yang, C.~Zhang, J.~Lu, J.~Qian, S.~He, P.~Zhao, B.~Qiao, R.~Huang, S.~Qin, Q.~Su, J.~Ye, Y.~Zhang, J.-G. Lou, Q.~Lin, S.~Rajmohan, D.~Zhang, and Q.~Zhang, ``Large action models: From inception to implementation,'' \emph{arXiv preprint arXiv:2412.10047}, Jan 2025, [Online]. Available: https://arxiv.org/abs/2412.10047. [Accessed: Mar. 14, 2025].

\bibitem{tran2025multiagent}
K.-T. Tran, D.~Dao, M.-D. Nguyen, Q.-V. Pham, B.~O'Sullivan, and H.~D. Nguyen, ``Multi-agent collaboration mechanisms: A survey of llms,'' \emph{arXiv preprint arXiv:2501.06322}, Jan 2025, [Online]. Available: https://arxiv.org/abs/2501.06322. [Accessed: Mar. 14, 2025].

\bibitem{zhang2024xlam}
J.~Zhang, T.~Lan, M.~Zhu, Z.~Liu, T.~Hoang, S.~Kokane, W.~Yao, J.~Tan, A.~Prabhakar, H.~Chen, Z.~Liu, Y.~Feng, T.~Awalgaonkar, R.~Murthy, E.~Hu, Z.~Chen, R.~Xu, J.~C. Niebles, S.~Heinecke, H.~Wang, S.~Savarese, and C.~Xiong, ``xlam: A family of large action models to empower ai agent systems,'' \emph{arXiv preprint arXiv:2409.03215}, Sep 2024, [Online]. Available: https://arxiv.org/abs/2409.03215. [Accessed: Mar. 14, 2025].

\bibitem{yang2024llmbased}
Y.~Yang, Q.~Peng, J.~Wang, Y.~Wen, and W.~Zhang, ``Llm-based multi-agent systems: Techniques and business perspectives,'' \emph{arXiv preprint arXiv:2411.14033}, Dec 2024, [Online]. Available: https://arxiv.org/abs/2411.14033. [Accessed: Mar. 14, 2025].

\bibitem{han2024llm}
S.~Han, Q.~Zhang, Q.~Yao, W.~Jin, Z.~Xu, and X.~He, ``Llm multi-agent systems: Challenges and open problems,'' \emph{arXiv preprint arXiv:2402.03578}, Feb 2024, [Online]. Available: https://arxiv.org/abs/2402.03578. [Accessed: Mar. 14, 2025].

\end{thebibliography}
